# -*- coding: utf-8 -*-
"""Face Expression Detection .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DVJkT0Ka21JYo0xA_3PviIybs8Iy57d_
"""

import tensorflow as tf
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from tensorflow.keras.models import model_from_json
import seaborn as sns
from keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt
import os

from sklearn.metrics import confusion_matrix
from mlxtend.plotting import plot_confusion_matrix

import seaborn as sns
import keras
from keras import models
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.optimizers import RMSprop,Adam
from keras.utils import to_categorical
from keras.preprocessing.image import ImageDataGenerator

path = 'https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset/data'

data =("https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset/data")

def plot_all_emotions():
    fig, axs = plt.subplots(1, 7, figsize=(30, 12))
    fig.subplots_adjust(hspace = .2, wspace=.2)
    axs = axs.ravel()
    for i in range(7):
        idx = data[data['emotion']==i].index[i]
        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')
        axs[i].set_title(emotions[train_labels[idx].argmax()])
        axs[i].set_xticklabels([])
        axs[i].set_yticklabels([])

def prepare_data(data):
    """ Prepare data for modeling
        input: data frame with labels und pixel data
        output: image and label array """

    image_array = np.zeros(shape=(len(data), 48, 48))
    image_label = np.array(list(map(int, data['emotion'])))

    for i, row in enumerate(data.index):
        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')
        image = np.reshape(image, (48, 48))
        image_array[i] = image

    return image_array, image_label

def plot_compare_distributions(array1, array2, title1='', title2=''):
    df_array1 = pd.DataFrame()
    df_array2 = pd.DataFrame()
    df_array1['emotion'] = array1.argmax(axis=1)
    df_array2['emotion'] = array2.argmax(axis=1)

    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)
    x = emotions.values()

    y = df_array1['emotion'].value_counts()
    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))
    for key_missed in keys_missed:
        y[key_missed] = 0
    axs[0].bar(x, y.sort_index(), color='orange')
    axs[0].set_title(title1)
    axs[0].grid()

    y = df_array2['emotion'].value_counts()
    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))
    for key_missed in keys_missed:
        y[key_missed] = 0
    axs[1].bar(x, y.sort_index())
    axs[1].set_title(title2)
    axs[1].grid()

    plt.show()

emotion_label_to_text = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}

class_weight = dict(zip(range(0, 7), (((data[data[' Usage']=='Training']['emotion'].value_counts()).sort_index())/len(data[data[' Usage']=='Training']['emotion'])).tolist()))
class_weight

from imblearn.under_sampling import RandomUnderSampler, TomekLinks
from imblearn.over_sampling import RandomOverSampler, SMOTE
from imblearn.pipeline import Pipeline

from collections import Counter
emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}

train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])
val_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])
test_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])
pp = Pipeline([('tk',TomekLinks()),('ros',RandomOverSampler(random_state=0))])
train_image_array, train_image_label = pp.fit_resample(train_image_array.reshape(train_image_array.shape[0],48*48), train_image_label)
print(Counter(train_image_label))
train_image_array = train_image_array.reshape(train_image_array.shape[0], 48, 48)

train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))
train_images = train_images.astype('float32')
val_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))
val_images = val_images.astype('float32')
test_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))
test_images = test_images.astype('float32')

train_labels = tf.keras.utils.to_categorical(train_image_label)
val_labels = tf.keras.utils.to_categorical(val_image_label)
test_labels = tf.keras.utils.to_categorical(test_image_label)

train_images.shape

val_images.shape

test_images.shape

# Visualizing emotion count

plot_compare_distributions(train_labels, val_labels, title1='train labels', title2='val labels')

# Visualize the data

plot_all_emotions()

model = Sequential([
    Conv2D(32, (3,3), activation = 'relu', padding = 'same', input_shape = (48,48,1)),
    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),
    MaxPooling2D(2,2),
    Dropout(0.25),
    BatchNormalization(),

    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),
    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),
    MaxPooling2D(2,2),
    Dropout(0.25),
    BatchNormalization(),

    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),
    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),
    MaxPooling2D(2,2),
    Dropout(0.25),
    BatchNormalization(),

    Flatten(),

    Dense(64, activation='relu'),
    Dropout(0.25),
    Dense(32, activation='relu'),
    Dropout(0.25),
    BatchNormalization(),
    Dense(7, activation='softmax')
])

model.summary()

model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])

# Commented out IPython magic to ensure Python compatibility.
# %time

history = model.fit(train_images, train_labels,
                    validation_data=(val_images, val_labels),
                    class_weight = class_weight,
                    epochs=50,
                    batch_size=64)

test_loss, test_acc = model.evaluate(test_images, test_labels)
print('test accuracy:', test_acc)

loss = history.history['loss']
loss_val = history.history['val_loss']
epochs = range(1, len(loss)+1)
plt.plot(epochs, loss, 'bo', label='loss_train')
plt.plot(epochs, loss_val, 'b', label='loss_val')
plt.title('value of the loss function')
plt.xlabel('epochs')
plt.ylabel('value of the loss function')
plt.legend()
plt.grid()
plt.show()

acc = history.history['accuracy']
acc_val = history.history['val_accuracy']
epochs = range(1, len(loss)+1)
plt.plot(epochs, acc, 'bo', label='accuracy_train')
plt.plot(epochs, acc_val, 'b', label='accuracy_val')
plt.title('accuracy')
plt.xlabel('epochs')
plt.ylabel('value of accuracy')
plt.legend()
plt.grid()
plt.show()

datagen = ImageDataGenerator(
    rescale=1/255,
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)

datagen.fit(train_images)
datagen.fit(val_images)
datagen.fit(test_images)

# Commented out IPython magic to ensure Python compatibility.
# %time

h1 = model.fit(datagen.flow(train_images, train_labels),
                    validation_data=datagen.flow(val_images, val_labels),
                    class_weight = class_weight,
                    epochs=40,
                    batch_size=64)

history = h1.history
tf.keras.backend.set_value(model.optimizer.learning_rate, 0.0001)

# Commented out IPython magic to ensure Python compatibility.
# %time

h2 = model.fit(datagen.flow(train_images, train_labels),
                    validation_data=datagen.flow(val_images, val_labels),
                    class_weight = class_weight,
                    epochs=40,
                    batch_size=64)

for k in history.keys():
    history[k] += h2.history[k]

test_loss, test_acc = model.evaluate(test_images, test_labels)
print('test accuracy:', test_acc)

loss = history['loss']
loss_val = history['val_loss']
epochs = range(1, len(loss)+1)
plt.plot(epochs, loss, 'bo', label='loss_train')
plt.plot(epochs, loss_val, 'b', label='loss_val')
plt.title('value of the loss function')
plt.xlabel('epochs')
plt.ylabel('value of the loss function')
plt.legend()
plt.grid()
plt.show()

acc = history['accuracy']
acc_val = history['val_accuracy']
epochs = range(1, len(loss)+1)
plt.plot(epochs, acc, 'bo', label='accuracy_train')
plt.plot(epochs, acc_val, 'b', label='accuracy_val')
plt.title('accuracy')
plt.xlabel('epochs')
plt.ylabel('value of accuracy')
plt.legend()
plt.grid()
plt.show()

def expand_greyscale_image_channels(grey_pil_image):
    grey_image_arr = np.array(grey_pil_image)
    grey_image_arr_3_channel = grey_image_arr.repeat(3, axis=-1)
    return grey_image_arr_3_channel

train_images_rgb = np.zeros(shape=(49182, 48, 48, 3), dtype=int)
for i in range (len(train_images)):
    train_images_rgb[i] = expand_greyscale_image_channels(train_images[i])

val_images_rgb = np.zeros(shape=(3589, 48, 48, 3), dtype=int)
for i in range (len(val_images)):
    val_images_rgb[i] = expand_greyscale_image_channels(val_images[i])

test_images_rgb = np.zeros(shape=(3589, 48, 48, 3), dtype=int)
for i in range (len(test_images)):
    test_images_rgb[i] = expand_greyscale_image_channels(test_images[i])

base_model = tf.keras.applications.VGG16(
    input_shape=(48,48,3),
    include_top=False,
    weights='imagenet'
)

base_model.trainable = False

base_model.summary()

np.random.seed(1)
tf.random.set_seed(1)

model3 = Sequential([
    base_model,
    BatchNormalization(),

    Flatten(),

    Dense(256, activation='relu'),
    Dropout(0.25),
    Dense(128, activation='relu'),
    Dropout(0.25),
    Dense(64, activation='relu'),
    Dropout(0.25),
    Dense(32, activation='relu'),
    Dropout(0.25),
    BatchNormalization(),
    Dense(7, activation='softmax')
])

model3.summary()

opt = tf.keras.optimizers.Adam(0.0001)
model3.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

# Commented out IPython magic to ensure Python compatibility.
# %time

h3 = model3.fit(datagen.flow(train_images_rgb, train_labels),
                    validation_data=datagen.flow(val_images_rgb, val_labels),
                    class_weight = class_weight,
                    epochs=40,
                    batch_size=64)

history3 = h3.history

loss = history3['loss']
loss_val = history3['val_loss']
epochs = range(1, len(loss)+1)
plt.plot(epochs, loss, 'bo', label='loss_train')
plt.plot(epochs, loss_val, 'b', label='loss_val')
plt.title('value of the loss function')
plt.xlabel('epochs')
plt.ylabel('value of the loss function')
plt.legend()
plt.grid()
plt.show()

acc = history3['accuracy']
acc_val = history3['val_accuracy']
epochs = range(1, len(loss)+1)
plt.plot(epochs, acc, 'bo', label='accuracy_train')
plt.plot(epochs, acc_val, 'b', label='accuracy_val')
plt.title('accuracy')
plt.xlabel('epochs')
plt.ylabel('value of accuracy')
plt.legend()
plt.grid()
plt.show()

base_model.trainable = True
opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.00001)
model3.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

# Commented out IPython magic to ensure Python compatibility.
# %time

h4 = model3.fit(datagen.flow(train_images_rgb, train_labels),
                    validation_data=datagen.flow(val_images_rgb, val_labels),
                    class_weight = class_weight,
                    epochs=40,
                    batch_size=64)

pred_test_labels = model3.predict(test_images_rgb)

df_compare = pd.DataFrame()
df_compare['real'] = test_labels.argmax(axis=1)
df_compare['pred'] = pred_test_labels.argmax(axis=1)
df_compare['wrong'] = np.where(df_compare['real']!=df_compare['pred'], 1, 0)

conf_mat = confusion_matrix(test_labels.argmax(axis=1), pred_test_labels.argmax(axis=1))

fig, ax = plot_confusion_matrix(conf_mat=conf_mat,
                                show_normed=True,
                                show_absolute=False,
                                class_names=emotions.values(),
                                figsize=(8, 8))
fig.show()

test_loss, test_acc = model3.evaluate(test_images_rgb, test_labels)
print('test accuracy:', test_acc)